# brokers集群
kafka.producer.bootstrap.servers=192.168.57.130:9092
kafka.producer.acks=all
#发送失败重试次数
kafka.producer.retries=3
kafka.producer.linger.ms=10
# 33554432 即32MB的批处理缓冲区
kafka.producer.buffer.memory=40960
#批处理条数：当多个记录被发送到同一个分区时，生产者会尝试将记录合并到更少的请求中。这有助于客户端和服务器的性能
kafka.producer.batch.size=4096
kafka.producer.defaultTopic=test0811
kafka.producer.key.serializer=org.apache.kafka.common.serialization.StringSerializer
kafka.producer.value.serializer=org.apache.kafka.common.serialization.StringSerializer
################# kafka consumer ##################
kafka.consumer.bootstrap.servers=192.168.57.130:9092
# 如果为true，消费者的偏移量将在后台定期提交
kafka.consumer.enable.auto.commit=true
#如何设置为自动提交（enable.auto.commit=true），这里设置自动提交周期
kafka.consumer.auto.commit.interval.ms=1000 
#order-beta 消费者群组ID，发布-订阅模式，即如果一个生产者，多个消费者都要消费，那么需要定义自己的群组，同一群组内的消费者只有一个能消费到消息
##kafka.consumer.group.id=test-consumer-group
#在使用Kafka的组管理时，用于检测消费者故障的超时
kafka.consumer.session.timeout.ms=30000
kafka.consumer.key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
kafka.consumer.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer